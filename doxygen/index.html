<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Noodle: Noodle</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Noodle
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('index.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Noodle </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="mainpage"></a> Noodle is a lightweight <b>CNN-style inference</b> library designed for microcontrollers and other memory-constrained systems. Its primary design principle is <b>streaming-based execution</b>: instead of storing all intermediate tensors in RAM, Noodle can read inputs and weights from external storage and write intermediate activations back to storage. This approach allows the peak memory footprint to remain small and predictable.</p>
<p>This documentation describes the public API, as well as the core invariants—data layouts, file formats, and buffer requirements—needed to use Noodle correctly and safely.</p>
<hr  />
<h1><a class="anchor" id="autotoc_md1"></a>
What Noodle is (and is NOT)</h1>
<h2><a class="anchor" id="autotoc_md2"></a>
Noodle is:</h2>
<ul>
<li>A compact set of C/C++ functions for mainly <b>convolution, activation, pooling, flattening, fully connected,</b> style pipelines.</li>
<li>Designed for <b>memory-constrained environments</b>, with APIs that support file-backed I/O to avoid large <code>W×W×C</code> allocations.</li>
<li>Backend-agnostic at the call site: filesystem operations are routed through a small abstraction layer (see <a class="el" href="group__noodle__fs.html">Filesystem backend layer</a>).</li>
</ul>
<h2><a class="anchor" id="autotoc_md3"></a>
Noodle is NOT:</h2>
<ul>
<li>A training framework (no automatic differentiation or optimizers).</li>
<li>A dynamic tensor runtime with graph scheduling.</li>
<li>A replacement for highly optimized vendor DSP or accelerator libraries; its focus is clarity, portability, and pedagogical transparency.</li>
</ul>
<hr  />
<h1><a class="anchor" id="autotoc_md5"></a>
Key design concepts</h1>
<h2><a class="anchor" id="autotoc_md6"></a>
Streaming-first memory model</h2>
<p>A common failure mode in embedded machine learning is that models work in desktop environments but exceed the memory limits of microcontrollers. This is largely due to tensor sizes scaling as <code>W×W×C</code>.</p>
<p>Noodle addresses this issue through a streaming execution model:</p>
<ul>
<li>Inputs may reside on external storage.</li>
<li>Each layer consumes an input tensor (or file).</li>
<li>The output is written to a new file.</li>
<li>Only small working buffers are kept in RAM.</li>
</ul>
<p>This design explains why multiple function variants exist, such as <b>file → file</b>, <b>memory → file</b>, and <b>file → memory</b> operations.</p>
<hr  />
<h2><a class="anchor" id="autotoc_md8"></a>
Data layout conventions</h2>
<p>Noodle uses explicit and consistent layout conventions to maintain predictability across platforms.</p>
<p><b>CHW file layout (feature maps on storage):</b></p><ul>
<li><p class="startli">Channel planes are stored sequentially:</p>
<p class="startli"><code>[ch0 plane][ch1 plane] … [chC−1 plane]</code></p>
</li>
</ul>
<p><b>HWC-flatten layout (common for in-memory outputs):</b></p><ul>
<li><p class="startli">Pixel-major interleaving of channels:</p>
<p class="startli"><code>out[(y·W + x)·C + c]</code></p>
</li>
</ul>
<p>When mixing streaming and in-memory operations, ensure that the appropriate layout conversions are applied (for example, flattening or reordering).</p>
<hr  />
<h1><a class="anchor" id="autotoc_md10"></a>
Quick start</h1>
<h2><a class="anchor" id="autotoc_md11"></a>
1) Select a filesystem backend (compile time)</h2>
<p>Enable a backend using build flags. The exact macros may vary by platform. None means all no external file storage is needed.</p>
<ul>
<li>SD via SdFat: <code>NOODLE_USE_SDFAT</code></li>
<li>FFat: <code>NOODLE_USE_FFAT</code></li>
<li>LittleFS: <code>NOODLE_USE_LITTLEFS</code></li>
<li>None: : <code>NOODLE_USE_NONE</code></li>
</ul>
<p>See: noodle_config and <a class="el" href="group__noodle__fs.html">Filesystem backend layer</a>.</p>
<hr  />
<h2><a class="anchor" id="autotoc_md13"></a>
2) Provide working buffers</h2>
<p>Noodle relies on a small number of reusable <b>temporary buffers</b>, typically two, that are shared across layer calls. This approach stabilizes peak memory usage, but it introduces several constraints:</p>
<ul>
<li>Buffers must be allocated and sized appropriately.</li>
<li>Calls are not re-entrant.</li>
<li>Concurrent use from multiple threads is not supported without isolation.</li>
</ul>
<p>In RTOS-based systems, treat Noodle as a single-threaded worker unless separate instances and buffers are provided.</p>
<hr  />
<h2><a class="anchor" id="autotoc_md15"></a>
3) Construct a processing pipeline</h2>
<p>A typical streaming pipeline follows this pattern:</p>
<div class="fragment"><div class="line"><span class="comment">// file → file convolution</span></div>
<div class="line"><a class="code hl_function" href="group__noodle__public.html#ga31bf8b8e6222200a0099ccefa27cbd8a">noodle_conv_float</a>(<span class="stringliteral">&quot;in.bin&quot;</span>, Cin, Cout, <span class="stringliteral">&quot;c1.bin&quot;</span>, W, conv1, pool1, NULL);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// next convolution stage</span></div>
<div class="line"><a class="code hl_function" href="group__noodle__public.html#ga31bf8b8e6222200a0099ccefa27cbd8a">noodle_conv_float</a>(<span class="stringliteral">&quot;c1.bin&quot;</span>, Cout, Cout2, <span class="stringliteral">&quot;c2.txt&quot;</span>, V, conv2, pool2, NULL);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// flatten for fully connected head</span></div>
<div class="line"><a class="code hl_function" href="group__noodle__public.html#ga00eae91c6064d79c299a3a5893db967f">noodle_flat</a>(<span class="stringliteral">&quot;c2.txt&quot;</span>, flat_mem, V2, Cout2);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// dense + softmax</span></div>
<div class="line"><a class="code hl_function" href="group__noodle__public.html#ga173bcc3844c49c58115ddc09ca144027">noodle_fcn</a>(flat_mem, out_scores, ...);</div>
<div class="ttc" id="agroup__noodle__public_html_ga00eae91c6064d79c299a3a5893db967f"><div class="ttname"><a href="group__noodle__public.html#ga00eae91c6064d79c299a3a5893db967f">noodle_flat</a></div><div class="ttdeci">uint16_t noodle_flat(const char *in_fn, float *output, uint16_t V, uint16_t n_filters)</div><div class="ttdef"><b>Definition</b> noodle.cpp:898</div></div>
<div class="ttc" id="agroup__noodle__public_html_ga173bcc3844c49c58115ddc09ca144027"><div class="ttname"><a href="group__noodle__public.html#ga173bcc3844c49c58115ddc09ca144027">noodle_fcn</a></div><div class="ttdeci">uint16_t noodle_fcn(const int8_t *input, uint16_t n_inputs, uint16_t n_outputs, const char *out_fn, const FCNFile &amp;fcn, CBFPtr progress_cb)</div><div class="ttdef"><b>Definition</b> noodle.cpp:937</div></div>
<div class="ttc" id="agroup__noodle__public_html_ga31bf8b8e6222200a0099ccefa27cbd8a"><div class="ttname"><a href="group__noodle__public.html#ga31bf8b8e6222200a0099ccefa27cbd8a">noodle_conv_float</a></div><div class="ttdeci">uint16_t noodle_conv_float(const char *in_fn, uint16_t n_inputs, uint16_t n_outputs, const char *out_fn, uint16_t W, const Conv &amp;conv, const Pool &amp;pool, CBFPtr progress_cb)</div><div class="ttdoc">File→File 2D conv with FLOAT input feature maps.</div><div class="ttdef"><b>Definition</b> noodle.cpp:637</div></div>
</div><!-- fragment --><p>In this model, <b>external storage effectively serves as activation memory</b>, enabling inference on devices with very limited RAM.</p>
<hr  />
<h1><a class="anchor" id="autotoc_md17"></a>
Training and parameter export workflow</h1>
<p>Noodle is an inference-only library. Model training is performed using standard deep learning frameworks such as Keras or PyTorch, after which the learned parameters are exported into a format suitable for embedded deployment.</p>
<p>A typical workflow consists of the following steps:</p>
<ol type="1">
<li><b>Model design and training</b><ul>
<li>Define a compact convolutional neural network (e.g., LeNet-style or MobileNet-style).</li>
<li>Train the model using Keras or PyTorch on a desktop or server environment.</li>
<li>Validate accuracy and adjust the architecture as needed.</li>
</ul>
</li>
<li><b>Parameter extraction</b><ul>
<li>After training, extract the learned weights and biases from each layer.</li>
<li>Convert them into a simple, deterministic layout suitable for embedded inference.</li>
<li>Typical parameters include:<ul>
<li>Weight matrices and bias vectors for convolution, depthwise convolution, and fully-connected layers</li>
<li>NO bias vectors for depthwise convolution</li>
<li>Batch-normalization parameters (gamma, beta, mean, variance)</li>
</ul>
</li>
</ul>
</li>
<li><p class="startli"><b>Export to Noodle-compatible format</b></p><ul>
<li>A lightweight model exporter script is provided to convert trained parameters into Noodle-compatible files.</li>
<li>The exporter generates:<ul>
<li><code>.h</code> header files containing C-style arrays for in-memory inference, and</li>
<li><code>.txt</code> files containing raw numeric parameters for streaming-based execution.</li>
</ul>
</li>
<li>Each layer is exported as a separate file (for example, <code>w01.h</code>, <code>bn01.txt</code>, etc.), following Noodle’s layout conventions.</li>
</ul>
<p class="startli">This dual-format export allows the same trained model to be deployed in:</p><ul>
<li><b>memory-resident mode</b> (using <code>.h</code> arrays), or</li>
<li><b>streaming mode</b> (using <code>.txt</code> files on SD or flash storage).</li>
</ul>
</li>
<li><b>Embedded deployment</b><ul>
<li>Copy exported parameter files to the target platform (flash, SD card, or filesystem).</li>
<li>Build the inference pipeline using Noodle APIs.</li>
<li>Run inference on the microcontroller.</li>
</ul>
</li>
</ol>
<p>By exposing the parameter extraction and deployment steps, Noodle provides a transparent, end-to-end TinyML workflow rather than a black-box runtime.</p>
<hr  />
<h1><a class="anchor" id="autotoc_md19"></a>
API overview</h1>
<p>The documentation is organized into the following modules:</p>
<ul>
<li>noodle_api — Core public API (layers, activations, pooling, flatten, etc.)</li>
<li><a class="el" href="group__noodle__fs.html">Filesystem backend layer</a> — Filesystem abstraction layer (SdFat, FFat, LittleFS)</li>
<li>noodle_config — Compile-time configuration options and defaults</li>
</ul>
<hr  />
<h1><a class="anchor" id="autotoc_md21"></a>
Limitations and considerations</h1>
<ul>
<li>Several helpers rely on shared global state (file handles and temporary buffers). <br  />
 Concurrent or re-entrant usage is not supported by default.</li>
<li>Some path utilities may use static internal buffers and are not thread-safe.</li>
<li><b>Certain APIs assume fixed dimensional structures.</b> <br  />
 In particular, feature maps are assumed to be square (<code>W×W</code>) in many parts of the API. Rectangular grids are not currently supported.</li>
<li><b>Convolution padding is symmetric only.</b> <br  />
 Current convolution routines assume uniform padding on all sides (for example, one pixel for a 3×3 kernel). <br  />
 Asymmetric or framework-specific padding modes are not supported.</li>
<li><b>Pooling operations use valid regions only.</b> <br  />
 Pooling layers do not apply padding. The pooling window is applied only to fully valid regions of the input feature map.</li>
</ul>
<p><b>Storage latency can dominate:</b> <br  />
 Many microcontrollers are compute-capable but I/O-bound. <br  />
</p>
<hr  />
<h1><a class="anchor" id="autotoc_md23"></a>
Glossary</h1>
<ul>
<li><b>CHW :</b> Channel-first planar storage; channels are stored as full planes.</li>
<li><b>HWC-flatten :</b> Pixel-major interleaved channels, commonly used before dense layers.</li>
<li><b>Streaming :</b> Moving tensors through external storage to reduce peak RAM usage.</li>
<li><b>Cin / Cout :</b> Input and output channel counts.</li>
<li><b>in-variable</b>: parameters / inputs / outputs that are stored in variables (variable mnemonic)</li>
<li><b>in-file</b>: Parameters / inputs / outputs that are stored in files (file mnemonic)</li>
</ul>
<hr  />
<p> : </p>
</div></div><!-- PageDoc -->
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8 </li>
  </ul>
</div>
</body>
</html>
